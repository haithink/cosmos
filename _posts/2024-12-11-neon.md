---
title: "NEON指令加速ORB描述符距离计算/AVX512加速"
date: 2024-12-11
tags: [c++, neon, simd]
---

使用NEON指令加速ORB描述符距离计算，核心是计算一个2进制整数中1的个数。自己折腾了一段时间，看了下开源代码[libpopcnt](https://github.com/kimwalisch/libpopcnt)，这里面倒是封装得不错，但一开始看得不仔细，以为NEON指令里面没用popcnt这样的指令，后面AI直接给了个方案，原来是有的，不过名字变成了**vcntq_u8**。

最终实现如下，可能节约30%的耗时吧。反正有了AI加持，初步学习和使用SIMD指令可以比以前快很多，但AI经常给出错误的实现，需要自己单步调试看看结果，这点也要注意。至于更高效地进行优化，还是需要很多经验和套路学习了。

```c++
#ifdef __ANDROID__
    int DescriptorDistanceNEON(const cv::Mat &a, const cv::Mat &b)
    {
        const int32_t *pa = a.ptr<int32_t>();
        const int32_t *pb = b.ptr<int32_t>();

        uint32x4_t dist_vec = vdupq_n_u32(0);  // Initialize a vector to hold distance results

        for (int i = 0; i < 8; i += 4, pa += 4, pb += 4)
        {
            // Load 4 integers from both descriptors
            uint32x4_t va = vld1q_u32(reinterpret_cast<const uint32_t*>(pa));
            uint32x4_t vb = vld1q_u32(reinterpret_cast<const uint32_t*>(pb));

            // XOR between descriptors
            uint32x4_t vxor = veorq_u32(va, vb);

            // Hamming weight calculation (using NEON population count instruction)
            uint8x16_t vpopcnt = vcntq_u8(vreinterpretq_u8_u32(vxor));

            // Sum the popcount for each 32-bit integer
            uint16x8_t vpopcnt16 = vpaddlq_u8(vpopcnt);
            uint32x4_t vpopcnt32 = vpaddlq_u16(vpopcnt16);
            dist_vec = vaddq_u32(dist_vec, vpopcnt32);  // Accumulate the result
        }

        // Horizontally sum the elements in dist_vec
        uint32_t dist[4];
        vst1q_u32(dist, dist_vec);
        return dist[0] + dist[1] + dist[2] + dist[3];
    }
#endif
```

后面又在支持AVX512指令的机器上进行加速。当然，首先要确保CPU支持AVX 512 FP计算。具体工具可以用https://github.com/nihui/ruapu.git。
CMakeLists里面加入编译选项
```cmake
CHECK_CXX_COMPILER_FLAG("-mavx512f" COMPILER_SUPPORTS_AVX512F)
if(COMPILER_SUPPORTS_AVX512F)
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -mavx512f")
else()
    message(WARNING "The compiler does not support AVX-512.")
endif()
```

代码中
```c++
    float DescriptorDistance(const cv::Mat &a, const cv::Mat &b)
    {
        // float dist = (float)cv::norm(a, b, cv::NORM_L2);
        // return dist;

        assert(a.type() == CV_32FC1 && b.type() == CV_32FC1);
        assert((a.cols % 16 ==0) && (b.cols % 16 ==0));
        assert(a.rows == 1 && b.rows == 1);

        const float* a_ptr = a.ptr<float>();
        const float* b_ptr = b.ptr<float>();

        __m512 sum = _mm512_setzero_ps();  // 初始化累加器为0

        const int block = b.cols / 16;


        for (int i = 0; i < block; i += 16) {
            __m512 va = _mm512_loadu_ps(a_ptr + i);  // 加载a的16个元素
            __m512 vb = _mm512_loadu_ps(b_ptr + i);  // 加载b的16个元素
            __m512 diff = _mm512_sub_ps(va, vb);     // 计算差值
            __m512 sq = _mm512_mul_ps(diff, diff);   // 计算平方
            sum = _mm512_add_ps(sum, sq);            // 累加到sum
        }

        // 将AVX-512寄存器中的值累加到一个标量中
        float result[16];
        _mm512_storeu_ps(result, sum);
        float l2_sum = 0.0f;
        for (int i = 0; i < 16; ++i) {
            l2_sum += result[i];
        }

        return std::sqrt(l2_sum);  // 返回L2距离        
    }

```
耗时比cv::norm节约2/3左右。
